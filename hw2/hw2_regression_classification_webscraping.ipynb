{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2018: Homework 02\n",
    "\n",
    "### Regression, Classification, Webscraping\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3), Alexander Fred-Ojala (Extra Credit)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction-classification, regression and web-scraping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file is uploaded to bCourses and is named: __Energy.csv__\n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1:Read the data file in python. Describe data features in terms of type, distribution range and mean values. Plot feature distributions.This step should give you clues about data sufficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1    float64\n",
       "X2    float64\n",
       "X3    float64\n",
       "X4    float64\n",
       "X5    float64\n",
       "X6      int64\n",
       "X7    float64\n",
       "X8      int64\n",
       "Y1    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy = pd.read_csv('Energy.csv')\n",
    "df_energy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764167</td>\n",
       "      <td>671.708333</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>176.604167</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>2.81250</td>\n",
       "      <td>22.307201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105777</td>\n",
       "      <td>88.086116</td>\n",
       "      <td>43.626481</td>\n",
       "      <td>45.165950</td>\n",
       "      <td>1.75114</td>\n",
       "      <td>1.118763</td>\n",
       "      <td>0.133221</td>\n",
       "      <td>1.55096</td>\n",
       "      <td>10.090196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.682500</td>\n",
       "      <td>606.375000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>140.875000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>12.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>673.750000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>183.750000</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>18.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>741.125000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>31.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>43.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4         X5          X6  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.00000  768.000000   \n",
       "mean     0.764167  671.708333  318.500000  176.604167    5.25000    3.500000   \n",
       "std      0.105777   88.086116   43.626481   45.165950    1.75114    1.118763   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.50000    2.000000   \n",
       "25%      0.682500  606.375000  294.000000  140.875000    3.50000    2.750000   \n",
       "50%      0.750000  673.750000  318.500000  183.750000    5.25000    3.500000   \n",
       "75%      0.830000  741.125000  343.000000  220.500000    7.00000    4.250000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.00000    5.000000   \n",
       "\n",
       "               X7         X8          Y1  \n",
       "count  768.000000  768.00000  768.000000  \n",
       "mean     0.234375    2.81250   22.307201  \n",
       "std      0.133221    1.55096   10.090196  \n",
       "min      0.000000    0.00000    6.010000  \n",
       "25%      0.100000    1.75000   12.992500  \n",
       "50%      0.250000    3.00000   18.950000  \n",
       "75%      0.400000    4.00000   31.667500  \n",
       "max      0.400000    5.00000   43.100000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "X1    768 non-null float64\n",
      "X2    768 non-null float64\n",
      "X3    768 non-null float64\n",
      "X4    768 non-null float64\n",
      "X5    768 non-null float64\n",
      "X6    768 non-null int64\n",
      "X7    768 non-null float64\n",
      "X8    768 non-null int64\n",
      "Y1    768 non-null float64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_energy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11348d358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwEAAAJOCAYAAADvZgsYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIceoAaoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1138c20b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_energy.boxplot()\n",
    "df_energy.hist(figsize=(13,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __REGRESSION__:\n",
    "LABELS ARE CONTINUOUS VALUES.\n",
    "Here the model is trained to predict a continuous value for each instance.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a continuous value  for  that instance.  \n",
    "\n",
    "__Q2.1: Train a linear regression model on 85 percent of the given dataset, what is the intercept value and coefficient values.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6.51273538e+01   5.45865377e+11  -5.45865377e+11  -1.09173075e+12\n",
      "   4.31875224e+00   2.03479748e-02   1.97104305e+01   2.06084437e-01]\n",
      "82.2604785605\n"
     ]
    }
   ],
   "source": [
    "df_train = df_energy.sample(frac=0.85, random_state=1)\n",
    "df_test = df_energy.loc[~df_energy.index.isin(df_train.index)]\n",
    "df_train.head()\n",
    "#'Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height','Orientation',\n",
    "#'Glazing Area','Glazing Area Distribution'\n",
    "x_train=df_train[['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "y_train=df_train['Y1']\n",
    "x_test=df_test[['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "y_test=df_test['Y1']\n",
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "lrm = linear_model.LinearRegression()\n",
    "lrm.fit(x_train, y_train)\n",
    "print(lrm.coef_)\n",
    "print(lrm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### Q.2.2: Report model performance using 'ROOT MEAN SQUARE' error metric on:  \n",
    "__1. Data that was used for training(Training error)__   \n",
    "__2. On the 15 percent of unseen data (test error) __ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 2.95218574892\n",
      "test error: 2.80015514166\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = lrm.predict(x_train)\n",
    "rms2_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print('training error:',rms2_train)\n",
    "\n",
    "y_pred_test = lrm.predict(x_test)\n",
    "rms2_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print('test error:',rms2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__ Q2.3: Lets us see the effect of amount of data on the performance of prediction model.Use varying amounts of  Training data (100,200,300,400,500,all) to train regression models and report  training error and validation error in each case. Validation data/Test data   is the same as above for  all  these cases.__  \n",
    "\n",
    "Plot error rates vs number of training examples.Comment on the relationshipyou observe in the plot, between the amount of data used to train the model and the validation accuracy of the model.\n",
    "\n",
    "__Hint:__ Use array indexing to choose varying data amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 300, 400, 500, 653] [8.3561195237888182, 10.361883393606144, 9.5714840328655164, 8.9740758905807745, 8.7348930645252594, 8.7154006961395538] [7.5159980074304942, 7.755206066962324, 7.6203573519467396, 7.7011008063122368, 7.6905107157680597, 7.8408688173774665]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116375eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=[100,200,300,400,500,len(x_train)]\n",
    "reg = LinearRegression()\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "for i in index:\n",
    "    X_train=x_train[:i]\n",
    "    Y_train=y_train[:i]\n",
    "    reg.fit(X_train, Y_train)\n",
    "    Y_pred_train = reg.predict(X_train)\n",
    "    Y_pred_test = reg.predict(x_test)\n",
    "    train_err = mean_squared_error(Y_train, Y_pred_train)\n",
    "    test_err = mean_squared_error(y_test, Y_pred_test)\n",
    "    train_errors.append(train_err)\n",
    "    test_errors.append(test_err)\n",
    "print(index, train_errors, test_errors)\n",
    "plt.plot(index, train_errors, index, test_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__CLASSIFICATION__:\n",
    "LABELS ARE DISCRETE VALUES.\n",
    "Here the model is trained to classify each instance into a set of predefined  discrete classes.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a  class of that instance. You can also output the probabilities of an instance belnging to a class.  \n",
    "\n",
    "__ Q 3.1:  Bucket values of 'y1' i.e 'Heating Load'  from the original dataset into 3 classes:__ \n",
    "\n",
    "0: 'Low' ( < 15),   \n",
    "1: 'Medium'  (15-30),   \n",
    "2: 'High'  (>30)\n",
    "\n",
    "This converts the given dataset  into a classification problem, classes being, Heating load is: *low, medium or high*. Use this datset with transformed 'heating load' for creating a  logistic regression classifiction model that predicts heating load type of a building. Use test-train split ratio of 0.15.  \n",
    "\n",
    "*Report training and test accuracies and  confusion matrices.*\n",
    "\n",
    "\n",
    "**HINT:** Use pandas.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ran/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y1 class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1     X2     X3     X4   X5  X6   X7  X8     Y1 Y1 class\n",
       "7   0.90  563.5  318.5  122.5  7.0   5  0.0   0  19.68        1\n",
       "10  0.86  588.0  294.0  147.0  7.0   4  0.0   0  19.34        1\n",
       "15  0.82  612.5  318.5  147.0  7.0   5  0.0   0  15.98        1\n",
       "22  0.76  661.5  416.5  122.5  7.0   4  0.0   0  24.77        1\n",
       "25  0.74  686.0  245.0  220.5  3.5   3  0.0   0   6.05        0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Y1 class\"] = pd.cut(df_test['Y1'], [0,15,30,100000],3, labels=['0','1','2'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Q3.2: One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. This makes training less sensitive to the scale of features . Scaling is important in algorithms that use distance based classification, SVM or K means or involve gradient descent optimization.If we  Scale features in the range [0,1] it is called unity based normalization.__\n",
    "\n",
    "__Perform unity based normalization on the above dataset and train the model again, compare model performance in training and validation with your previous model.__  \n",
    "\n",
    "refer:http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "more at: https://en.wikipedia.org/wiki/Feature_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy of train data: 36.96 %\n",
      "Logistic Regression accuracy of validation data: 30.17 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x=df_energy[['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "y=df_energy['Y1']\n",
    "y = y.apply(np.int64)\n",
    "\n",
    "x_minmax = min_max_scaler.fit_transform(x)\n",
    "x_train_minmax, x_test_minmax, y_train, y_test = train_test_split(x_minmax, y, test_size=0.15)\n",
    "\n",
    "logreg = LogisticRegression() # instantiate\n",
    "logreg.fit(x_train_minmax,y_train) # fit\n",
    "y_pred_train_minmax = logreg.predict(x_train_minmax) # predict\n",
    "y_pred_test_minmax = logreg.predict(x_test_minmax) # predict\n",
    "\n",
    "acc_log = sum(y_pred_train_minmax == y_train)/len(y_train)*100\n",
    "print('Logistic Regression accuracy of train data:', str(round(acc_log,2)),'%')\n",
    "\n",
    "y_pred_minmax_test = logreg.predict(x_test_minmax) # predict\n",
    "acc_log = sum(y_pred_test_minmax == y_test)/len(y_test)*100\n",
    "print('Logistic Regression accuracy of validation data:', str(round(acc_log,2)),'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__ 1. Read __`diabetesdata.csv`__ file into a pandas dataframe. Analyze the data features, check for NaN values. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "__ 2. Preprocess data to replace NaN values in a feature(if any) using mean of the feature.  \n",
    "Train  logistic regression, SVM, perceptron, kNN, xgboost and random forest models using this preprocessed data with 20% test split.Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace NaN\n",
    "df_diabetes = pd.read_csv('diabetesdata.csv')\n",
    "df_diabetes['TimesPregnant'].fillna((df_diabetes['TimesPregnant'].mean()), inplace=True)\n",
    "df_diabetes['glucoseLevel'].fillna((df_diabetes['glucoseLevel'].mean()), inplace=True)\n",
    "df_diabetes['BP'].fillna((df_diabetes['BP'].mean()), inplace=True)\n",
    "df_diabetes['insulin'].fillna((df_diabetes['insulin'].mean()), inplace=True)\n",
    "df_diabetes['BMI'].fillna((df_diabetes['BMI'].mean()), inplace=True)\n",
    "df_diabetes['Pedigree'].fillna((df_diabetes['Pedigree'].mean()), inplace=True)\n",
    "df_diabetes['Age'].fillna((df_diabetes['Age'].mean()), inplace=True)\n",
    "df_diabetes['IsDiabetic'].fillna((df_diabetes['IsDiabetic'].mean()), inplace=True)\n",
    "df_train1 = df_diabetes.sample(frac=0.8, random_state=1)\n",
    "df_test1 = df_diabetes.loc[~df_energy.index.isin(df_train.index)]\n",
    "x_train1=df_train1[['TimesPregnant','glucoseLevel','BP','insulin','BMI','Pedigree','Age']]\n",
    "y_train1=df_train1['IsDiabetic']\n",
    "x_test1=df_test1[['TimesPregnant','glucoseLevel','BP','insulin','BMI','Pedigree','Age']]\n",
    "y_test1=df_test1['IsDiabetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bays\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier #stochastic gradient descent\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.85\n",
      "76.52\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "lg = LogisticRegression()\n",
    "lg.fit(x_train1, y_train1)\n",
    "y_lg_pred_train = lg.predict(x_train1)\n",
    "y_lg_pred_test = lg.predict(x_test1)\n",
    "acc_train_lg = round(lg.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_lg = round(lg.score(x_test1, y_test1) * 100, 2) \n",
    "print(acc_train_lg)\n",
    "print(acc_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "63.48\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "svc = svm.SVC()\n",
    "svc.fit(x_train1, y_train1)\n",
    "y_lg_pred_train = svc.predict(x_train1)\n",
    "y_lg_pred_test = svc.predict(x_test1)\n",
    "acc_train_lg = round(svc.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_lg = round(svc.score(x_test1, y_test1) * 100, 2) \n",
    "print(acc_train_lg)\n",
    "print(acc_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.36\n",
      "37.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ran/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train1, y_train1)\n",
    "y_perceptron_pred_train = perceptron.predict(x_train1)\n",
    "y_perceptron_pred_test = perceptron.predict(x_test1)\n",
    "acc_train_perceptron = round(perceptron.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_perceptron = round(perceptron.score(x_test1, y_test1) * 100, 2) \n",
    "print(acc_train_perceptron)\n",
    "print(acc_test_perceptron)\n",
    "# When I change python2 to python3, the warning messgae keeps showing up and I don't know if it has anything to do with the result,\n",
    "# which is quite low comparing to other models. I have cleared output and re-run for several times, the result stays same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.32\n",
      "72.17\n"
     ]
    }
   ],
   "source": [
    "#kNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train1, y_train1)\n",
    "y_knn_pred_train = knn.predict(x_train1)\n",
    "y_knn_pred_test = knn.predict(x_test1)\n",
    "acc_train_knn = round(knn.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_knn = round(knn.score(x_test1, y_test1) * 100, 2) \n",
    "print(acc_train_knn)\n",
    "print(acc_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "74.78\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "xgboost = xgb.XGBClassifier(n_estimators=1000)\n",
    "xgboost.fit(x_train1, y_train1)\n",
    "y__xgboost_train = xgboost.predict(x_train1)\n",
    "y_xgboost_pred_test = xgboost.predict(x_test1)\n",
    "acc_train_xgboost = round(xgboost.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_xgboost = round(xgboost.score(x_test1, y_test1) * 100, 2) \n",
    "print(acc_train_xgboost)\n",
    "print(acc_test_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "71.3\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(x_train1, y_train1)\n",
    "y__rf_train = rf.predict(x_train1)\n",
    "y_rf_pred_test = rf.predict(x_test1)\n",
    "acc_train_rf = round(rf.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_rf = round(rf.score(x_test1, y_test1) * 100, 2) \n",
    "print(acc_train_rf)\n",
    "print(acc_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__3. What is the  ratio of diabetic persons in 3 equirange bands of 'BMI' and 'Pedigree' in the provided dataset.__\n",
    "\n",
    " __Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BP_df</th>\n",
       "      <th>insulin_df</th>\n",
       "      <th>BMI_df</th>\n",
       "      <th>Pedigree_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BP_df insulin_df BMI_df Pedigree_df\n",
       "0     1          0      1           0\n",
       "1     1          0      1           0\n",
       "2     1          0      1           0\n",
       "3     1          0      1           0\n",
       "4     0          0      1           2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['BP_df'] = pd.cut(df_diabetes['BP'], 3, labels=['0','1','2'])\n",
    "df['insulin_df'] = pd.cut(df_diabetes['insulin'],3, labels=['0','1','2'])\n",
    "df['BMI_df'] = pd.cut(df_diabetes['BMI'],3, labels=['0','1','2'])\n",
    "df['Pedigree_df'] = pd.cut(df_diabetes['Pedigree'],3, labels=['0','1','2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__4. Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group.We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetesdata.csv')\n",
    "dataset.BP = pd.cut(dataset.BP, 3, labels=[0,1,2])\n",
    "dataset.BMI = pd.cut(dataset.BMI, 3, labels=[0,1,2])\n",
    "dataset.Pedigree = pd.cut(dataset.Pedigree, 3, labels=[0,1,2])\n",
    "\n",
    "data=[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess_Age table:\n",
      " [[24 25 55]\n",
      " [29 29 37]\n",
      " [33 32 31]]\n",
      "Guess_glucoseLevel table:\n",
      " [[115 127 137]\n",
      " [112 115 149]\n",
      " [133 129 159]]\n",
      "\n",
      "Assigning age and glucoseLevel values to NAN age and glucoseLevel values in the dataset...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel BP  insulin BMI Pedigree  Age  IsDiabetic\n",
       "0              6           148  1        0   1        0   50           1\n",
       "1              1           112  1        0   1        0   31           0\n",
       "2              8           183  1        0   1        0   29           1\n",
       "3              1           112  1       94   1        0   21           0\n",
       "4              0           137  0      168   1        2   33           1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_ages = np.zeros((3,3),dtype=int)\n",
    "guess_gl = np.zeros((3,3),dtype=int)\n",
    "                    \n",
    "for i in range(0, 3):\n",
    "    for j in range(0,3):\n",
    "        guess_df_age = dataset[(dataset['BMI'] == i) \\\n",
    "                    &(dataset['BP'] == j)]['Age'].dropna()\n",
    "        guess_df_gl = dataset[(dataset['BP'] == i) \\\n",
    "                    &(dataset['Pedigree'] == j)]['glucoseLevel'].dropna()\n",
    "            # Extract the median age for this group\n",
    "            # (less sensitive) to outliers\n",
    "        age_guess = guess_df_age.median()\n",
    "        gl_guess = guess_df_gl.median()\n",
    "            # Convert random age float to int\n",
    "        guess_ages[i,j] = int(age_guess)\n",
    "        guess_gl[i,j] = int(gl_guess)\n",
    "        \n",
    "print('Guess_Age table:\\n',guess_ages)\n",
    "print('Guess_glucoseLevel table:\\n',guess_gl)\n",
    "print ('\\nAssigning age and glucoseLevel values to NAN age and glucoseLevel values in the dataset...')\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    for j in range(0, 3):\n",
    "        dataset.loc[ (dataset.Age.isnull()) & (dataset.BMI == i) \\\n",
    "                & (dataset.BP == j),'Age'] = guess_ages[i,j]\n",
    "        dataset.loc[ (dataset.glucoseLevel.isnull()) & (dataset.BP == i) \\\n",
    "                & (dataset.Pedigree == j),'glucoseLevel'] = guess_gl[i,j]                    \n",
    "\n",
    "dataset['Age'] = dataset['Age'].astype(int)\n",
    "dataset['glucoseLevel'] = dataset['glucoseLevel'].astype(int)\n",
    "print()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__5. Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 5 categories each.__\n",
    "\n",
    "__Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 20% test split. Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.Age = pd.cut(dataset.Age, 5, labels=[0,1,2,3,4])\n",
    "dataset.glucoseLevel = pd.cut(dataset.glucoseLevel, 5, labels=[0,1,2,3,4])\n",
    "x = dataset.drop(\"IsDiabetic\", axis=1) \n",
    "y = dataset[\"IsDiabetic\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train for logistic regression: 75.57\n",
      "accuracy of test for logistic regression: 77.27\n",
      "accuracy of train for Perceptron : 66.61\n",
      "accuracy of test for Perceptron : 70.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ran/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train for randomforest : 95.28\n",
      "accuracy of test for randomforest : 75.32\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "lg = LogisticRegression()\n",
    "lg.fit(x_train1, y_train1)\n",
    "y_lg_pred_train = lg.predict(x_train1)\n",
    "y_lg_pred_test = lg.predict(x_test1)\n",
    "acc_train_lg = round(lg.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_lg = round(lg.score(x_test1, y_test1) * 100, 2) \n",
    "print('accuracy of train for logistic regression:', acc_train_lg)\n",
    "print('accuracy of test for logistic regression:', acc_test_lg)\n",
    "\n",
    "#perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train1, y_train1)\n",
    "y_perceptron_pred_train = perceptron.predict(x_train1)\n",
    "y_perceptron_pred_test = perceptron.predict(x_test1)\n",
    "acc_train_perceptron = round(perceptron.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_perceptron = round(perceptron.score(x_test1, y_test1) * 100, 2) \n",
    "print('accuracy of train for Perceptron :', acc_train_perceptron)\n",
    "print('accuracy of test for Perceptron :', acc_test_perceptron)\n",
    "\n",
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(x_train1, y_train1)\n",
    "y__rf_train = rf.predict(x_train1)\n",
    "y_rf_pred_test = rf.predict(x_test1)\n",
    "acc_train_rf = round(rf.score(x_train1, y_train1) * 100, 2) \n",
    "acc_test_rf = round(rf.score(x_test1, y_test1) * 100, 2) \n",
    "print('accuracy of train for randomforest :',acc_train_rf)\n",
    "print('accuracy of test for randomforest :', acc_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "1. __Derive the expression for the optimal parameters in the linear regression equation, i.e. solve the normal equation for Ordinary Least Squares for the case of Simple Linear Regression, when we only have one input and one output__\n",
    "\n",
    "Given a set of _n_ points $(X_i,Y_i)$ where $Yi$ is dependent on $Xi$ by a linear relation,  find the best-fit line,$$Z_i = {aX_i + b}$$  that minimizes the __sum of squared errors in Y__,i.e: $$minimize \\sum_{i}{(Y_i- Z_i)^2}$$\n",
    "__i. __ Show that $$ intercept \\quad b = \\overline{Y}-  a.\\overline{X}\\quad  and   \\quad slope \\quad a= \\frac{\\sum_{i}(X_i- \\overline{X})\u0001(Y_i- \\overline{Y})^2}{ \\sum_{i}(X_i- \\overline{X})}$$\n",
    "\n",
    "\n",
    " where $\\overline{X}$ and  $\\overline{Y}$ are the averages of the X values and the Y values, respectively.\n",
    " \n",
    "__ ii. __Show that slope _a_ can be written as $ a = r.(S_y /S_x)$ where $S_y$  = the standard deviation of the Y values and $S_x$= the standard deviation of the X values and _r_ is the correlation coefficient.\n",
    "\n",
    "##### Please try to write a nice LateXed version of your answer, and do the derivations of the expressions as nicely as possible\n",
    "\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "i. \n",
    "Given a set of n points ($X_i$,$Y_i$) where $Y_i$ is dependent on $X_i$ by a linear relation, find the best-fit line,\n",
    "$Z_i$=aX_i+b$\n",
    "\n",
    "To that minimizes the sum of squared errors in Y,i.e:\n",
    "\\begin{equation}\n",
    "minimize\\sum_i{(Y_i-Z_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "Suppose $SSE=min\\sum_i{(Y_i-Z_i)^2}$\n",
    "\n",
    "let $\\frac{\\partial SSE}{\\partial b}=\\sum{(2b-2(Y_i-aX_i))}$=$2nb-2\\sum(X_i)$=$2nb=2n\\bar Y+2an\\bar X$=0\n",
    "\n",
    "We can get\n",
    "\\begin{equation}\n",
    "a=\\frac{\\sum(Y_i-\\bar Y)(X_i-\\bar X)}{\\sum(X_i-\\bar X)^2}\n",
    "\\end{equation}\n",
    "\n",
    "ii.\n",
    "\n",
    "$a=r.(\\frac{S_y}{S_x})=\\frac{cov(x,y)}{S_y.S_x}*\\frac{cov(x,y)}{Var(x)}=\\frac{n.cov(x,y)}{n.Var(x)}=\\frac{\\sum(Y_i-\\bar Y)(X_i-\\bar X)}{\\sum(X_i-\\bar X)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Extra Credit Points: Fun with Webscraping & Text manipulation\n",
    "### (Mandatory for Grad students!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'> `NOTE:` **If you are a Graduate Section student (enrolled in 290), the Extra Credit Questions are mandatory.**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Statistics in Presidential Debates\n",
    "\n",
    "Your first task is to scrape Presidential Debates from the Commission of Presidential Debates website: http://www.debates.org/index.php?page=debate-transcripts.\n",
    "\n",
    "To do this, you are not allowed to manually look up the URLs that you need, instead you have to scrape them. The root url to be scraped is the one listed above, namely: http://www.presidency.ucsb.edu/debates.php\n",
    "\n",
    "\n",
    "1. By using `requests` and `BeautifulSoup` find all the links / URLs on the website that links to transcriptions of **First Presidential Debates** from the years [2012, 2008, 2004, 2000, 1996, 1988, 1984, 1976, 1960]. In total you should find 9 links / URLs tat fulfill this criteria.\n",
    "2. When you have a list of the URLs your task is to create a Data Frame with some statistics (see example of output below):\n",
    "    1. Scrape the title of each link and use that as the column name in your Data Frame. \n",
    "    2. Count how long the transcript of the debate is (as in the number of characters in transcription string). Feel free to include `\\` characters in your count, but remove any breakline characters, i.e. `\\n`. You will get credit if your count is +/- 10% from our result.\n",
    "    3. Count how many times the word **war** was used in the different debates. Note that you have to convert the text in a smart way (to not count the word **warranty** for example, but counting **war.**, **war!**, **war,** or **War** etc.\n",
    "    4. Also scrape the most common used word in the debate, and write how many times it was used. Note that you have to use the same strategy as in 3 in order to do this.\n",
    "    \n",
    "**Tips:**\n",
    "\n",
    "___\n",
    "\n",
    "In order to solve question 3 and 4 above it can be useful to work with Regular Expressions and explore methods on strings like `.strip(), .replace(), .find(), .count(), .lower()` etc. Both are very powerful tools to do string processing in Python. To count common words for example I used a `Counter` object and a Regular expression pattern for only words, see example:\n",
    "\n",
    "```python\n",
    "    from collections import Counter\n",
    "    import re\n",
    "\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", text.lower()))\n",
    "```\n",
    "\n",
    "Read more about Regular Expressions here: https://docs.python.org/3/howto/regex.html\n",
    "    \n",
    "    \n",
    "**Example output of all of the answers to EC Question 1:**\n",
    "\n",
    "\n",
    "![pres_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/president_stats.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\")) \n",
    "from __future__ import division, print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re\n",
    "import lxml.html\n",
    "import urllib\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info aboutOctober 3, 2012: The First Obama-Romney Presidential Debate: http://www.debates.org/index.php?page=october-3-2012-debate-transcript\n",
      "Info aboutSeptember 26, 2008: The First McCain-Obama Presidential Debate: http://www.debates.org/index.php?page=2008-debate-transcript\n",
      "Info aboutSeptember 30, 2004: The First Bush-Kerry Presidential Debate: http://www.debates.org/index.php?page=september-30-2004-debate-transcript\n",
      "Info aboutOctober 3, 2000: The First Gore-Bush Presidential Debate: http://www.debates.org/index.php?page=october-3-2000-transcript\n",
      "Info aboutOctober 6, 1996: The First Clinton-Dole Presidential Debate: http://www.debates.org/index.php?page=october-6-1996-debate-transcript\n",
      "Info aboutSeptember 25, 1988: The First Bush-Dukakis Presidential Debate: http://www.debates.org/index.php?page=september-25-1988-debate-transcript\n",
      "Info aboutOctober 7, 1984: The First Reagan-Mondale Presidential Debate: http://www.debates.org/index.php?page=october-7-1984-debate-transcript\n",
      "Info aboutSeptember 23, 1976: The First Carter-Ford Presidential Debate: http://www.debates.org/index.php?page=september-23-1976-debate-transcript\n",
      "Info aboutSeptember 26, 1960: The First Kennedy-Nixon Presidential Debate: http://www.debates.org/index.php?page=september-26-1960-debate-transcript\n",
      "['http://www.debates.org/index.php?page=october-3-2012-debate-transcript', 'http://www.debates.org/index.php?page=2008-debate-transcript', 'http://www.debates.org/index.php?page=september-30-2004-debate-transcript', 'http://www.debates.org/index.php?page=october-3-2000-transcript', 'http://www.debates.org/index.php?page=october-6-1996-debate-transcript', 'http://www.debates.org/index.php?page=september-25-1988-debate-transcript', 'http://www.debates.org/index.php?page=october-7-1984-debate-transcript', 'http://www.debates.org/index.php?page=september-23-1976-debate-transcript', 'http://www.debates.org/index.php?page=september-26-1960-debate-transcript']\n"
     ]
    }
   ],
   "source": [
    "#jy\n",
    "source = requests.get('http://www.debates.org/index.php?page=debate-transcripts').content \n",
    "soup = bs.BeautifulSoup(source,'html.parser')\n",
    "links=soup.find_all('a')\n",
    "contents=[]\n",
    "urls=[]\n",
    "for i in links:\n",
    "    if ('First'in i.text) & ('Presidential'in i.text) & ('Debate'in i.text):\n",
    "        print(\"Info about{}:\".format(i.text),i.get('href'))\n",
    "        contents.append(i.text)\n",
    "        urls.append(i.get('href'))\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ran/anaconda2/envs/py3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ran/anaconda2/envs/py3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>October 3, 2012: The First Obama-Romney Presidential Debate</th>\n",
       "      <th>September 26, 2008: The First McCain-Obama Presidential Debate</th>\n",
       "      <th>September 30, 2004: The First Bush-Kerry Presidential Debate</th>\n",
       "      <th>October 3, 2000: The First Gore-Bush Presidential Debate</th>\n",
       "      <th>October 6, 1996: The First Clinton-Dole Presidential Debate</th>\n",
       "      <th>September 25, 1988: The First Bush-Dukakis Presidential Debate</th>\n",
       "      <th>October 7, 1984: The First Reagan-Mondale Presidential Debate</th>\n",
       "      <th>September 23, 1976: The First Carter-Ford Presidential Debate</th>\n",
       "      <th>September 26, 1960: The First Kennedy-Nixon Presidential Debate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Debate char length</th>\n",
       "      <td>94594</td>\n",
       "      <td>182386</td>\n",
       "      <td>82685</td>\n",
       "      <td>91040</td>\n",
       "      <td>93057</td>\n",
       "      <td>87458</td>\n",
       "      <td>86654</td>\n",
       "      <td>80701</td>\n",
       "      <td>60901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war_count</th>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common_w</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common_w_count</th>\n",
       "      <td>757</td>\n",
       "      <td>1470</td>\n",
       "      <td>857</td>\n",
       "      <td>919</td>\n",
       "      <td>876</td>\n",
       "      <td>803</td>\n",
       "      <td>865</td>\n",
       "      <td>856</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    October 3, 2012: The First Obama-Romney Presidential Debate  \\\n",
       "Debate char length                                               94594            \n",
       "war_count                                                            3            \n",
       "most_common_w                                                      the            \n",
       "most_common_w_count                                                757            \n",
       "\n",
       "                    September 26, 2008: The First McCain-Obama Presidential Debate  \\\n",
       "Debate char length                                              182386               \n",
       "war_count                                                           44               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                               1470               \n",
       "\n",
       "                    September 30, 2004: The First Bush-Kerry Presidential Debate  \\\n",
       "Debate char length                                               82685             \n",
       "war_count                                                           64             \n",
       "most_common_w                                                      the             \n",
       "most_common_w_count                                                857             \n",
       "\n",
       "                    October 3, 2000: The First Gore-Bush Presidential Debate  \\\n",
       "Debate char length                                               91040         \n",
       "war_count                                                           11         \n",
       "most_common_w                                                      the         \n",
       "most_common_w_count                                                919         \n",
       "\n",
       "                    October 6, 1996: The First Clinton-Dole Presidential Debate  \\\n",
       "Debate char length                                               93057            \n",
       "war_count                                                           14            \n",
       "most_common_w                                                      the            \n",
       "most_common_w_count                                                876            \n",
       "\n",
       "                    September 25, 1988: The First Bush-Dukakis Presidential Debate  \\\n",
       "Debate char length                                               87458               \n",
       "war_count                                                            8               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                                803               \n",
       "\n",
       "                    October 7, 1984: The First Reagan-Mondale Presidential Debate  \\\n",
       "Debate char length                                               86654              \n",
       "war_count                                                            2              \n",
       "most_common_w                                                      the              \n",
       "most_common_w_count                                                865              \n",
       "\n",
       "                    September 23, 1976: The First Carter-Ford Presidential Debate  \\\n",
       "Debate char length                                               80701              \n",
       "war_count                                                            7              \n",
       "most_common_w                                                      the              \n",
       "most_common_w_count                                                856              \n",
       "\n",
       "                    September 26, 1960: The First Kennedy-Nixon Presidential Debate  \n",
       "Debate char length                                               60901               \n",
       "war_count                                                            3               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                                778               "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = None\n",
    "\n",
    "for link in urls:\n",
    "    debate = requests.get(link)\n",
    "    debate = debate.content\n",
    "    debate = BeautifulSoup(debate)\n",
    "    debate_content = debate.find(\"div\", {\"id\": \"content-sm\"})\n",
    "    debate_content = debate_content.find_all(\"p\")\n",
    "\n",
    "    text = None\n",
    "    for content in debate_content:\n",
    "        if (text!=None):\n",
    "            text = text + content.text\n",
    "        else:\n",
    "            text = content.text\n",
    "\n",
    "\n",
    "    text = text.replace(\"\\n\", \"\").replace(\"\\'\", \"'\")\n",
    "    # print(len(text))\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", text.lower()))\n",
    "    # print(counts.most_common()[0])\n",
    "    # print(counts[\"war\"])\n",
    "\n",
    "    # entry = [headings[0]]\n",
    "    entry = [len(text)]\n",
    "    entry.append(counts[\"war\"])\n",
    "    entry.append(counts.most_common()[0][0])\n",
    "    entry.append(counts.most_common()[0][1])\n",
    "    \n",
    "    if (entries!=None):\n",
    "        entries.append(entry)\n",
    "    else:\n",
    "        entries = [entry]\n",
    "\n",
    "entries\n",
    "row_names = [\"Debate char length\", \"war_count\", \"most_common_w\", \"most_common_w_count\"]\n",
    "\n",
    "df = pd.DataFrame(entries, index=contents, columns=row_names )\n",
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 2. Download and read in specific line from many data sets\n",
    "\n",
    "Scrape the first 27 data sets from this URL http://people.sc.fsu.edu/~jburkardt/datasets/regression/ (i.e.`x01.txt` - `x27.txt`). Then, save the 5th line in each data set, this should be the name of the data set author (get rid of the `#` symbol, the white spaces and the comma at the end). \n",
    "\n",
    "Count how many times (with a Python function) each author is the reference for one of the 27 data sets. Showcase your results, sorted, with the most common author name first and how many times he appeared in data sets. Use a Pandas DataFrame to show your results, see example.\n",
    "\n",
    "**Example output of the answer EC Question 2:**\n",
    "\n",
    "![author_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/data_authors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ran/anaconda2/envs/py3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ran/anaconda2/envs/py3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    R J Freund', 'P D Minton,']\n",
      "['#    D G Kleinbaum', 'L L Kupper,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    D G Kleinbaum', 'L L Kupper,']\n",
      "['#    K A Brownlee,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    S Chatterjee', 'B Price,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    R J Freund', 'P D Minton,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    Helmut Spaeth,']\n",
      "['#    S Chatterjee', 'B Price,']\n",
      "['#    S Chatterjee', 'B Price,']\n",
      "['#    S Chatterjee', 'B Price,']\n",
      "['#    S C Narula', 'J F Wellington,']\n",
      "['#    S C Narula', 'J F Wellington,']\n",
      "['Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'R J Freund', 'P D Minton', 'D G Kleinbaum', 'L L Kupper', 'Helmut Spaeth', 'D G Kleinbaum', 'L L Kupper', 'K A Brownlee', 'Helmut Spaeth', 'Helmut Spaeth', 'S Chatterjee', 'B Price', 'Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'R J Freund', 'P D Minton', 'Helmut Spaeth', 'Helmut Spaeth', 'Helmut Spaeth', 'S Chatterjee', 'B Price', 'S Chatterjee', 'B Price', 'S Chatterjee', 'B Price', 'S C Narula', 'J F Wellington', 'S C Narula', 'J F Wellington']\n",
      "Counter({'Helmut Spaeth': 16, 'S Chatterjee': 4, 'B Price': 4, 'R J Freund': 2, 'P D Minton': 2, 'D G Kleinbaum': 2, 'L L Kupper': 2, 'S C Narula': 2, 'J F Wellington': 2, 'K A Brownlee': 1})\n"
     ]
    }
   ],
   "source": [
    "datasets =[\"%02d\" % x for x in range(1,28)]\n",
    "print(datasets)\n",
    "authors = []\n",
    "for i in datasets:\n",
    "    result = requests.get(\"http://people.sc.fsu.edu/~jburkardt/datasets/regression/x\"+ format(i)+\".txt\")\n",
    "    soup = BeautifulSoup(result.content)\n",
    "    text = soup.find(\"p\").text.splitlines()\n",
    "    author = re.split(' and |, ',text[4])\n",
    "    print(author)\n",
    "    for name in author:\n",
    "        authors.append(name.replace(\"#    \", \"\").replace(\",\", \"\"))\n",
    "print(authors)\n",
    "#set(authors)\n",
    "j=Counter(authors)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helmut Spaeth</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S Chatterjee</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B Price</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R J Freund</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P D Minton</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D G Kleinbaum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L L Kupper</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S C Narula</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J F Wellington</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K A Brownlee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Authors  Counts\n",
       "0   Helmut Spaeth      16\n",
       "6    S Chatterjee       4\n",
       "7         B Price       4\n",
       "1      R J Freund       2\n",
       "2      P D Minton       2\n",
       "3   D G Kleinbaum       2\n",
       "4      L L Kupper       2\n",
       "8      S C Narula       2\n",
       "9  J F Wellington       2\n",
       "5    K A Brownlee       1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(j, orient='index').reset_index()\n",
    "df = df.rename(columns={'index':'Authors', 0:'Counts'})\n",
    "df = df.sort_values(by='Counts', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
